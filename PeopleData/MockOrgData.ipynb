{"cells":[{"cell_type":"code","source":["%pip install faker\n","%pip install networkx #needed only for display of the org graph, not to generate the data"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3073479c-8308-46ee-a33a-f9bae9cc3a5b"},{"cell_type":"code","source":["#Generates mock organization data\n","import pandas as pd\n","import datetime\n","import random\n","from faker import Faker\n","Faker.seed(50)\n"," \n","# Initialize the data\n","data = []\n","levels = 5\n","numberofdivisions = 10\n","maxperlevel = 9\n","minperlevel = 5\n","emaildomain = '@mockorg.com'\n","minhiredate = datetime.date(year=1990, month=1, day=1)\n","maxhiredate = datetime.date(year=2024, month=10, day=10)\n","fake = Faker()\n"," \n","# CEO\n","data.append({'EmployeeID': 1, 'SupervisorID': 1, 'Level': 1, 'Name': 'Susan McCEO', 'Email': 'susan_mcceo' + emaildomain, 'DOB': '1975-08-28', 'HireDate': '2010-06-05', 'Supervisor': 'Y', 'DivisionID': 1})\n","df = pd.DataFrame(data)\n"," \n","orglevels = range(2,levels+1)\n","empid = 2\n"," \n","for orglevel in orglevels:\n","    prevlevel = orglevel - 1\n","    prevlevelrows = df[df['Level'] == prevlevel]\n"," \n","    for index, row in prevlevelrows.iterrows():\n","        random.seed(row['EmployeeID'])\n","        if orglevel == 2:\n","            numofreports = numberofdivisions\n","        else:\n","            numofreports = random.randint(minperlevel, maxperlevel)\n","        reports = range(1,numofreports+1)\n","        if numofreports > 0 and orglevel < levels:\n","            supe = 'Y'\n","        else:\n","            supe = 'N'\n","        \n","        for report in reports:\n","            empname = fake.unique.name()\n","            empemail = empname.replace(\" \", \"_\").lower() + emaildomain\n","\n","            if orglevel == 2:\n","                divid = empid\n","            else:\n","                divid = row['DivisionID']\n","            df = pd.concat([df, pd.DataFrame([{'EmployeeID': empid, 'SupervisorID': row['EmployeeID'], 'Level': orglevel, 'Name': empname, 'Email': empemail,\n","                'DOB':fake.date_of_birth(minimum_age = 18, maximum_age = 60), 'HireDate': fake.date_between(start_date=minhiredate, end_date=maxhiredate), 'Supervisor': supe, 'DivisionID': divid}])], ignore_index=True)\n","            empid = empid + 1\n","\n","    print(df.shape)\n","\n","# Create divisions dataframe\n","divisions = {'Division': ['CEO', 'Finance', 'HR', 'R&D', 'Manufacturing', 'Sales', 'Utilities', 'Marketing', 'IT', 'Quality', 'Legal', 'Operations', 'External', 'Communications', 'Discovery'], 'DivisionID': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]}\n","df_divs = pd.DataFrame(divisions)\n","\n","# Merge/Add Division\n","org = pd.merge(df, df_divs, on=\"DivisionID\")\n","# Display the DataFrame\n","display(org)\n","print('Final' + str(org.shape))"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false,"jupyterDisplayViewState":{"tableOptions":{},"chartOptions":{"chartType":"bar","categoryFieldKeys":["3"],"seriesFieldKeys":["3"],"aggregationType":"count","isStacked":false,"binsNumber":10,"wordFrequency":"-1"},"viewOptionsGroup":[{"tabItems":[{"type":"table","name":"Table","key":"0","options":{}},{"type":"chart","key":"1","name":"Chart 1","options":{"chartType":"bar","categoryFieldKeys":[],"seriesFieldKeys":[],"aggregationType":"sum","isStacked":false,"binsNumber":10,"wordFrequency":"-1"}}]}]}},"id":"4b7fcc98-ae32-425e-a1e8-86dea25ec787"},{"cell_type":"code","source":["# write org to csv\n","import pandas as pd\n","wsid = 'd6a0d49e-3d96-4d1f-8962-d98c5fe99611'\n","lakehouseid = '0d178ea6-89ce-40b5-aa5d-3a03f1abef14'\n","rowcount = str(org.shape[0])\n","org.to_csv(f'abfss://{wsid}@onelake.dfs.fabric.microsoft.com/{lakehouseid}/Files/MockOrg_{rowcount}.csv', index=False)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b864c373-b90d-462e-9eda-dfaa733a7b2e"},{"cell_type":"code","source":["#Display top 3 levels of org chart\n","import pandas as pd\n","import networkx as nx\n","import matplotlib.pyplot as plt\n","\n","#Load data and convert to Pandas\n","displaydf = df[df['Level']<=3]\n","display(displaydf)\n","\n","parentcolumn = 'SupervisorID'\n","childcolumn = 'EmployeeID'\n","\n","# Create a NetworkX directed graph from the DataFrame\n","G = nx.from_pandas_edgelist(displaydf, source=f'{parentcolumn}', target=f'{childcolumn}', create_using=nx.DiGraph())\n","# nx.draw(G, with_labels=True)\n","nx.draw_kamada_kawai(G, with_labels=True)\n","plt.show()\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false,"editable":true,"run_control":{"frozen":false}},"id":"eaa2af64-a202-49e1-941b-285b34dad20a"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"jupyter","language":"Jupyter","display_name":"Jupyter"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"0d178ea6-89ce-40b5-aa5d-3a03f1abef14","default_lakehouse_name":"PeopleDataLH","default_lakehouse_workspace_id":"d6a0d49e-3d96-4d1f-8962-d98c5fe99611"}}},"nbformat":4,"nbformat_minor":5}