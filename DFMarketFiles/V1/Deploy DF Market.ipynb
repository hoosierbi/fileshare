{"cells":[{"cell_type":"code","source":["# Define item names, get Workspace ID\n","# Use notebook utils to get WS id and save as variable, then get each item id after it is generated\n","thisworkspaceid = spark.conf.get(\"trident.workspace.id\")\n","Name_Dataflow_EmptySalesTable = \"CreateOrEmpty_Sales_Table\"\n","Name_Dataflow_AppendSalesTable = \"Append_Sales_Table\"\n","Name_Dataflow_ReplaceDIMTables = \"Replace_DIM_Tables\"\n","Name_Pipeline_GenerateData = \"Generate Data\""],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a73261ce-c258-4009-9d1f-62d2d391af30"},{"cell_type":"code","source":["# Create DF Market Lakehouse\n","import requests\n","import pandas as pd\n","import sempy.fabric as fabric\n","from sempy.fabric.exceptions import FabricHTTPException, WorkspaceNotFoundException\n","\n","access_token = notebookutils.credentials.getToken(\"pbi\")\n","headers = {\"Authorization\": f\"Bearer {access_token}\",\n","            \"Content-Type\": \"application/json\"}\n","url = f\"https://api.fabric.microsoft.com/v1/workspaces/{thisworkspaceid}/lakehouses\"\n","body = {\n","  \"displayName\": \"DF_Market_LH\",\n","  \"description\": \"DF Market Lakehouse\"\n","}\n","response = requests.post(url, headers=headers, json=body)\n","jsonresponse = response.json()\n","print(jsonresponse)\n","lakehouseid = jsonresponse['id']"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9b04e8b4-786a-4ab8-8d6f-ca71276adafa"},{"cell_type":"code","source":["#Define Base64 Functions\n","import base64\n","\n","def tobase64(textstring):\n","    textstring_bytes = textstring.encode(\"ascii\")\n","    ascii_bytes = base64.b64encode(textstring_bytes)\n","    base64_output = ascii_bytes.decode(\"ascii\")\n","    return base64_output\n","\n","def frombase64(b64string):\n","    b64string_bytes = b64string.encode(\"ascii\")\n","    ascii_bytes2 = base64.b64decode(b64string_bytes)\n","    text_output = ascii_bytes2.decode(\"ascii\")\n","    return text_output\n","\n","# Define Item from Definition Function\n","def CreateItemFromDefinition(wsid, itemname, itemtype, itemdefinition):\n","    access_token = notebookutils.credentials.getToken(\"pbi\")\n","    headers = {\"Authorization\": f\"Bearer {access_token}\",\n","                \"Content-Type\": \"application/json\"}\n","    workspaceId = wsid     \n","    url = f\"https://api.fabric.microsoft.com/v1/workspaces/{workspaceId}/items\"\n","    body = {\n","        \"displayName\": itemname, \n","        \"type\": itemtype, \n","        \"definition\": itemdefinition\n","     }  \n","    response = requests.post(url, headers=headers, json = body)\n","    return response.json()"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2d3dbe57-8a48-46d3-9dcd-5735566a0ee1"},{"cell_type":"code","source":["# Create Dataflow - Empty Sales Table\n","import requests\n","import json5\n","\n","url = \"https://raw.githubusercontent.com/hoosierbi/fileshare/refs/heads/main/DFMarketFiles/V1/DataflowDefinition_EmptySalesTable.json\"\n","itemdef = requests.get(url).text\n","itemdef = itemdef.replace('replacewithworkspaceid', thisworkspaceid)\n","itemdef = itemdef.replace('replacewithlakehouseid', lakehouseid)\n","itemdef = json5.loads(itemdef)\n","itemdef['parts'][0]['payload'] = tobase64(itemdef['parts'][0]['payload'])\n","itemdef['parts'][1]['payload'] = tobase64(itemdef['parts'][1]['payload'])\n","itemdef['parts'][2]['payload'] = tobase64(itemdef['parts'][2]['payload'])\n","\n","createitem = CreateItemFromDefinition(thisworkspaceid, Name_Dataflow_EmptySalesTable, \"Dataflow\", itemdef)\n","print(createitem)\n","try:\n","    CreateSales_DataflowId = createitem['id']\n","except:\n","    print('fail')"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"bd754dcf-17a5-4936-9d53-5751a96e571e"},{"cell_type":"code","source":["# Create Dataflow - Append Sales Table\n","import requests\n","import json5\n","\n","url = \"https://raw.githubusercontent.com/hoosierbi/fileshare/refs/heads/main/DFMarketFiles/V1/DataflowDefinition_AppendSalesTable.json\"\n","itemdef = requests.get(url).text\n","itemdef = itemdef.replace('replacewithworkspaceid', thisworkspaceid)\n","itemdef = itemdef.replace('replacewithlakehouseid', lakehouseid)\n","itemdef = json5.loads(itemdef)\n","itemdef['parts'][0]['payload'] = tobase64(itemdef['parts'][0]['payload'])\n","itemdef['parts'][1]['payload'] = tobase64(itemdef['parts'][1]['payload'])\n","itemdef['parts'][2]['payload'] = tobase64(itemdef['parts'][2]['payload'])\n","\n","createitem = CreateItemFromDefinition(thisworkspaceid, Name_Dataflow_AppendSalesTable, \"Dataflow\", itemdef)\n","print(createitem)\n","try:\n","    AppendSales_DataflowId = createitem['id']\n","except:\n","    print('fail')"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"36915e56-9109-439d-b7ec-e328b2b147c7"},{"cell_type":"code","source":["# Create Dataflow - DIM Tables\n","import requests\n","import json5\n","\n","url = \"https://raw.githubusercontent.com/hoosierbi/fileshare/refs/heads/main/DFMarketFiles/V1/DataflowDefinition_ReplaceDIMTables.json\"\n","itemdef = requests.get(url).text\n","itemdef = itemdef.replace('replacewithworkspaceid', thisworkspaceid)\n","itemdef = itemdef.replace('replacewithlakehouseid', lakehouseid)\n","itemdef = json5.loads(itemdef)\n","itemdef['parts'][0]['payload'] = tobase64(itemdef['parts'][0]['payload'])\n","itemdef['parts'][1]['payload'] = tobase64(itemdef['parts'][1]['payload'])\n","itemdef['parts'][2]['payload'] = tobase64(itemdef['parts'][2]['payload'])\n","itemdef\n","createitem = CreateItemFromDefinition(thisworkspaceid, Name_Dataflow_ReplaceDIMTables, \"Dataflow\", itemdef)\n","print(createitem)\n","try:\n","    ReplaceDIMs_DataflowId = createitem['id']\n","except:\n","    print('fail')"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a890bb15-e449-40d6-b82e-a40ad0b92fc2"},{"cell_type":"code","source":["#Hard coded ids for troubleshooting\n","# lakehouseid = '3190cae1-4f77-45d5-bb3d-e5d60714e836'\n","# CreateSales_DataflowId = '5b9fbf44-7c9b-43bb-a63b-d8c29b0c806d'\n","# AppendSales_DataflowId = 'de68ac3e-7db6-4c98-9ae5-36c968dbab20'\n","# ReplaceDIMs_DataflowId = 'a72e870e-7aac-43b1-8bba-654f5800858f'"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"editable":false,"run_control":{"frozen":true}},"id":"339b487d-ffc7-40c0-be7a-f7e23efadf52"},{"cell_type":"code","source":["# Create Pipeline - Generate Data\n","#Change DIMs dataflow to not use params for WS and LH IDs\n","import requests\n","import json5\n","\n","url = \"https://raw.githubusercontent.com/hoosierbi/fileshare/refs/heads/main/DFMarketFiles/V1/PipelineDefinition_GenerateData.json\"\n","itemdef = requests.get(url).text\n","itemdef = itemdef.replace('replacewithworkspaceid', thisworkspaceid)\n","itemdef = itemdef.replace('replacewithlakehouseid', lakehouseid)\n","itemdef = itemdef.replace('CreateSalesDataflowId', CreateSales_DataflowId)\n","itemdef = itemdef.replace('ReplaceDIMsDataflowId', ReplaceDIMs_DataflowId)\n","itemdef = itemdef.replace('AppendSalesDataflowId', AppendSales_DataflowId)\n","itemdef = json5.loads(itemdef)\n","itemdef['parts'][0]['payload'] = tobase64(itemdef['parts'][0]['payload'])\n","itemdef['parts'][1]['payload'] = tobase64(itemdef['parts'][1]['payload'])\n","itemdef\n","\n","createitem = CreateItemFromDefinition(thisworkspaceid, Name_Pipeline_GenerateData, \"DataPipeline\", itemdef)\n","createitem\n","# GenerateData_PipelineId = createitem['id']"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"44c64a6e-f9a4-4946-a5ff-cbc595f71dc0"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}