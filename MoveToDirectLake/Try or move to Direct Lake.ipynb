{"cells":[{"cell_type":"markdown","source":["## Create a Direct Lake version of your semantic model and clone/rebind a report to it\n","### Useful if you want to:\n","- Take Direct Lake Mode for a spin - see how your model & report will perform before investing time in new ETL\n","- Create a Direct Lake replica of your model & report (typically use QSO for high concurrency, but this is an option too)\n","\n","Note - OneLake Integration must be enabled for your semantic model. Also use a Lakehouse **without** schema."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ec4ea9fa-a7fc-449d-9557-eda3a154029b"},{"cell_type":"code","source":["%pip install semantic-link-labs"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jupyter":{"source_hidden":false,"outputs_hidden":true},"nteract":{"transient":{"deleting":false}}},"id":"dbc0b5d6-89a8-4884-948d-e8a76f301f91"},{"cell_type":"code","source":["# Set all the names\n","ds_name = 'Flights43M'\n","new_ds_name = ds_name + '_OneLakeIntegration'\n","reportname = 'Flights43M'\n","new_reportname = reportname + '_OneLakeIntegration'\n","lakehouse_name = 'TryoutLH'"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"cd7847b1-ec04-42c0-ba22-be1592940d06"},{"cell_type":"code","source":["# Before you run this cell, OneLake Integration needs to be enabled for the semantic model\n","import sempy_labs as labs\n","labs.export_model_to_onelake(dataset=ds_name, destination_lakehouse=lakehouse_name)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jupyter":{"source_hidden":false,"outputs_hidden":true},"nteract":{"transient":{"deleting":false}}},"id":"0e8fd166-257b-45ab-b405-d3103cb92bed"},{"cell_type":"code","source":["# Before running this cell, make sure the desired LH is attached\n","import sempy.fabric as fabric\n","import sempy_labs as labs\n","from sempy_labs import directlake as dl \n","from sempy_labs import migration as mgrt\n","\n","# lh_tables = ['Airports', 'Carriers', 'ColumnsFP', 'Date', 'FieldPicker', 'Flights', 'MeasuresFP', 'MeasureTable', 'Planes', 'Time']\n","# lh_tables = ['Airports', 'Carriers', 'Date', 'Flights', 'MeasureTable', 'Planes', 'Time'] #list all tables that are not Field Parameters or calc groups\n","partitions = fabric.list_partitions(ds_name)\n","nonFPtablesList = partitions[~(partitions['Query'].str.contains('NAMEOF', na=False)) & ~(partitions['Source Type']=='CalculationGroup')]\n","lh_tables = nonFPtablesList['Table Name'].unique().tolist()\n","\n","# Create DL model based on LH\n","dl.generate_direct_lake_semantic_model(dataset = new_ds_name, lakehouse = lakehouse_name, lakehouse_tables = lh_tables)\n","\n","# Migrate model objects to new model\n","mgrt.migrate_model_objects_to_semantic_model(ds_name, new_ds_name)\n","mgrt.migrate_field_parameters(ds_name, new_ds_name)\n","\n","# Refresh the model\n","fabric.refresh_dataset(dataset=new_ds_name)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"44324245-a78b-4cd7-a120-b707a02576d4"},{"cell_type":"code","source":["# Validate Migration\n","validation_df = labs.migration.migration_validation(ds_name, new_ds_name)\n","print(validation_df.to_string())"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jupyter":{"source_hidden":false,"outputs_hidden":true},"nteract":{"transient":{"deleting":false}}},"id":"9b1d6767-ecb5-465a-9652-3e5738f87d64"},{"cell_type":"code","source":["# Clone the report\n","from sempy_labs import report as rpt\n","rpt.clone_report(reportname, new_reportname)\n","\n","# Bind new report to new model\n","rpt.report_rebind(new_reportname, new_ds_name)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"555f7993-6d2d-4e55-97a9-78b7e4e45fd6"},{"cell_type":"markdown","source":["## Permanently move to a Direct Lake model and clone/bind report to it\n","### Useful if you want to:\n","- take advantage of Direct Lake mode benefits (separate refresh and query, lower peak memory, reduce data duplication with table shortcuts, etc.)\n","- leverage other Fabric ETL options (pipeline, notebook, Dataflow Gen 2 instead of traditional import Power Query, Dataflow Gen 1)"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5519409e-1cb3-483b-9955-db991a68f2f6"},{"cell_type":"code","source":["# This cell is to create a model based on replacement OneLake tables, migrate model objects, and then clone/rebind the report\n","import sempy.fabric as fabric\n","import sempy_labs as labs\n","from sempy_labs import directlake as dl \n","from sempy_labs import migration as mgrt\n","from sempy_labs import report as rpt\n","\n","# Set all the names\n","ds_name = 'Flights43M'\n","new_ds_name = ds_name + '_NewTables'\n","reportname = 'Flights43M'\n","new_reportname = reportname + '_NewTables'\n","lakehouse_name = 'New_Tables_LH'\n","\n","# Get the list of tables from the current model (that are not Field Parameters or Calculation Groups)\n","partitions = fabric.list_partitions(ds_name)\n","nonFPtablesList = partitions[~(partitions['Query'].str.contains('NAMEOF', na=False)) & ~(partitions['Source Type']=='CalculationGroup')]\n","lh_tables = nonFPtablesList['Table Name'].unique().tolist()\n","\n","# Create DL model based on LH\n","dl.generate_direct_lake_semantic_model(dataset = new_ds_name, lakehouse = lakehouse_name, lakehouse_tables = lh_tables)\n","\n","# Migrate model objects to new model\n","mgrt.migrate_model_objects_to_semantic_model(ds_name, new_ds_name)\n","mgrt.migrate_field_parameters(ds_name, new_ds_name)\n","\n","# Refresh the model\n","fabric.refresh_dataset(dataset=new_ds_name)\n","\n","# Clone the report\n","rpt.clone_report(reportname, new_reportname)\n","\n","# Bind new report to new model\n","rpt.report_rebind(new_reportname, new_ds_name)\n","\n","# Validate Migration\n","# validation_df = labs.migration.migration_validation(ds_name, new_ds_name)\n","# print(validation_df.to_string())"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"719125ef-bb9c-4a65-bdaa-bc4e5296b2b8"}],"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"sessionKeepAliveTimeout":0,"kernel_info":{"name":"synapse_pyspark"},"language_info":{"name":"python"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"a365ComputeOptions":null,"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"3f05b247-f6e2-4565-afaf-91a262688896","default_lakehouse_name":"TryoutLH","default_lakehouse_workspace_id":"b692320f-419e-40ee-88aa-1cf6dec962ff"}}},"nbformat":4,"nbformat_minor":5}
